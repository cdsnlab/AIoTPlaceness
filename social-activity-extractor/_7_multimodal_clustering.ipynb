{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Clustering Analysis\n",
    "\n",
    "Sep 2019  \n",
    "Dongmin Kim\n",
    "[underkoo@kaist.ac.kr](mailto:underkoo@kaist.ac.kr)\n",
    "\n",
    "**Expected input data:**\n",
    "Process 900 dim latent feature of multi-modal instagram posts\n",
    "\n",
    "**What this script does:**  \n",
    "Explorative data analysis on the mult-modal latent. Checks for feature correlation (features = 900 dimesnsions), applies and visualized PCA, applies t-SNE on different data (raw, PCA, etc).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns; sns.set()\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from MulticoreTSNE import MulticoreTSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import SpectralClustering, AffinityPropagation, AgglomerativeClustering, KMeans, DBSCAN, OPTICS\n",
    "import matplotlib.colors as colors\n",
    "import math\n",
    "import time\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic line to have in-notebook interactive plots\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to use a korean words, unblock it!\n",
    "# path_gothic = './fonts/NanumBarunGothic.ttf'\n",
    "# fontprop1 = fm.FontProperties(fname=path_gothic, size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = config.Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load latent feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw data\n",
    "target_dataset = 'instagram0830'\n",
    "df_data = pd.read_csv(os.path.join(CONFIG.CSV_PATH, 'latent_' + target_dataset + '.csv'), index_col=0, header=None, encoding='utf-8-sig')\n",
    "df_data.index.name = 'short_code'\n",
    "#data_all = pd.read_csv('data/2019_05_01_naver_word2vec/word2vecBLOG)_1000.csv.zip', index_col=0, header=None)\n",
    "print('complete csv shape: ' + str(df_data.shape))\n",
    "print(df_data.iloc[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data seems to be well normalized to mean or median = 0 and std = 1\n",
    "plt.figure()\n",
    "df_data.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA as dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA(n_components=300)\n",
    "df_pca_data = pd.DataFrame(pca.fit_transform(df_data))\n",
    "df_pca_data.columns = ['PC' + str(i) for i in range(df_pca_data.shape[1])]\n",
    "df_pca_data.index = df_data.index\n",
    "print('singular_values_:\\n' + str(pca.singular_values_))\n",
    "print('components_:\\n' + str(pca.components_))\n",
    "\n",
    "# create PCA transformation DF\n",
    "df_pca_transformation = pd.DataFrame(pca.components_).transpose()\n",
    "df_pca_transformation.columns = ['PC' + str(i) for i in range(1, pca.n_components_ + 1)]\n",
    "df_pca_transformation.index = df_data.columns\n",
    "#print(df_pca_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA: plot variance explained\n",
    "plt.figure()\n",
    "plt.plot(pca.explained_variance_ratio_, marker='o', linestyle=':')\n",
    "plt.title('PCA: explained variance')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o', linestyle=':')\n",
    "plt.title('PCA: cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot_pointlabels(df_twocols, markersize=None):\n",
    "    # basic scatterplot\n",
    "    fig = plt.figure()\n",
    "    plt.plot(df_twocols.iloc[:, 0], df_twocols.iloc[:, 1], marker='.', linestyle='None', markersize=markersize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PC dimensions\n",
    "for dimen1 in range(0, 5):\n",
    "    for dimen2 in range(dimen1 + 1, 5):\n",
    "        # subset dataframe to the PC columns we need\n",
    "        df_tmp = df_pca_data.iloc[:, [dimen1, dimen2]]\n",
    "        \n",
    "        # plot without labels\n",
    "        scatterplot_pointlabels(df_tmp)\n",
    "        # plt.title(df_tmp.columns)\n",
    "        plt.xlabel(df_tmp.columns[0])\n",
    "        plt.ylabel(df_tmp.columns[1])\n",
    "        \n",
    "        # plot with labels\n",
    "        #scatterplot_pointlabels(df_tmp)\n",
    "        # plt.title(df_tmp.columns)\n",
    "        #plt.xlabel(df_tmp.columns[0])\n",
    "        #plt.ylabel(df_tmp.columns[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pca_data.to_csv(os.path.join(CONFIG.CSV_PATH, 'pca_' + target_dataset + '.csv'), encoding='utf-8-sig')\n",
    "df_pca_data = pd.read_csv(os.path.join(CONFIG.CSV_PATH, 'pca_' + target_dataset + '.csv'), index_col=0, header=0, encoding='utf-8-sig')\n",
    "df_pca_data.index.name = 'short_code'\n",
    "print(df_pca_data.iloc[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling(df_data, num_samples=100):\n",
    "    idx = int(len(df_data)/num_samples)\n",
    "    idx_list = [x for x in range(0, len(df_data), idx)]\n",
    "    return df_data.iloc[idx_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_data = downsampling(df_data, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_tsne(tsne_object, data_to_pass):\n",
    "    data_tsne = pd.DataFrame(tsne_object.fit_transform(data_to_pass))\n",
    "    data_tsne.index = data_to_pass.index\n",
    "    data_tsne.columns = [['tsne1', 'tsne2']]\n",
    "    return data_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on pca\n",
    "# TODO tune the learning rate and the iterations (rest should be ok i guess)\n",
    "start_time = time.time()\n",
    "#tsne_pca = do_tsne(TSNE(n_components=2, perplexity=50, early_exaggeration=12.0, learning_rate=100, n_iter=5000, random_state=42, verbose=1), ds_pca_data)\n",
    "ds_tsne_pca = do_tsne(MulticoreTSNE(n_components=2, perplexity=250, early_exaggeration=12.0, learning_rate=10, n_iter=1000, random_state=42, n_jobs=4, verbose=1), ds_pca_data)\n",
    "print(\"time elapsed: \" + str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot t-SNE with PCA\n",
    "scatterplot_pointlabels(ds_tsne_pca, 1)\n",
    "plt.title('t-SNE on PCA data')\n",
    "plt.savefig(os.path.join(CONFIG.SVG_PATH, 'ds_tsne_pca_' + target_dataset + '.svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_tsne_pca.iloc[:100])\n",
    "ds_tsne_pca.to_csv(os.path.join(CONFIG.CSV_PATH, 'ds_tsne_' + target_dataset + '.csv'), encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on pca\n",
    "# TODO tune the learning rate and the iterations (rest should be ok i guess)\n",
    "start_time = time.time()\n",
    "#tsne_pca = do_tsne(TSNE(n_components=2, perplexity=50, early_exaggeration=12.0, learning_rate=100, n_iter=5000, random_state=42, verbose=1), df_pca_data)\n",
    "tsne_pca = do_tsne(MulticoreTSNE(n_components=2, perplexity=500, learning_rate=10, n_iter=1000, random_state=42, n_jobs=4, verbose=1), df_pca_data)\n",
    "print(\"time elapsed: \" + str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot t-SNE with PCA\n",
    "scatterplot_pointlabels(tsne_pca, 0.2)\n",
    "plt.title('t-SNE on PCA data')\n",
    "plt.savefig(os.path.join(CONFIG.SVG_PATH, 'tsne_pca_' + target_dataset + '.svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne_pca.to_csv(os.path.join(CONFIG.CSV_PATH, 'tsne_' + target_dataset + '.csv'), encoding='utf-8-sig')\n",
    "tsne_pca = pd.read_csv(os.path.join(CONFIG.CSV_PATH, 'tsne_' + target_dataset + '.csv'), index_col=0, header=0, encoding='utf-8-sig')\n",
    "tsne_pca = tsne_pca.iloc[1:]\n",
    "tsne_pca.index.name = 'short_code'\n",
    "print(tsne_pca.iloc[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on raw data\n",
    "# TODO tune the learning rate and the iterations (rest should be ok i guess)\n",
    "# start_time = time.time()\n",
    "# tsne_raw = do_tsne(MulticoreTSNE(n_components=2, perplexity=400, early_exaggeration=12.0, learning_rate=100, n_iter=10000, random_state=42, n_jobs=4), data)\n",
    "# print(\"time elapsed: \" + str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot t-SNE with raw data\n",
    "# scatterplot_pointlabels(tsne_raw, plot_labels=False)\n",
    "# plt.title('t-SNE on raw data')\n",
    "# scatterplot_pointlabels(tsne_raw)\n",
    "# plt.title('t-SNE on raw data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow(X, max_num_clusters=10):\n",
    "    sse = []\n",
    "    for i in range(1, max_num_clusters):\n",
    "        start_time = time.time()\n",
    "        km = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
    "        km.fit(X)\n",
    "        print(\"time elapsed: \" + str(time.time()-start_time))\n",
    "        sse.append(km.inertia_)\n",
    "    fig = plt.figure()\n",
    "    plt.plot(range(1, max_num_clusters), sse, marker='o')\n",
    "    plt.xlabel('num of clusters')\n",
    "    plt.ylabel('SSE')\n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = elbow(tsne_pca, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = len(sse) - 1\n",
    "for i in range(1, last):\n",
    "    distance = abs((sse[last] - sse[0]) * i - (last - 0) * sse[i] + last * sse[0] - sse[last] * 0) / math.sqrt(math.pow((sse[last] - sse[0]),2) + math.pow((last - 0),2))\n",
    "    print(i, distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labeling points of tnse clusters\n",
    "def label_point(x, y, val, ax):\n",
    "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
    "    for i, point in a.iterrows():\n",
    "        ax.text(point['x']+.02, point['y'], str(point['val']), fontsize=3, fontproperties=fontprop1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spectral clustering\n",
    "#For using 'amg' you should install pyamg in you local computer.\n",
    "# Check the component at\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html\n",
    "start_time = time.time()\n",
    "clustering = DBSCAN(eps=3, min_samples=5).fit(tsne_pca)\n",
    "#clustering = SpectralClustering(n_clusters=num_clusters, assign_labels=\"discretize\", affinity= 'nearest_neighbors', n_neighbors=24, random_state=42, n_jobs=4).fit(df_pca_data)\n",
    "#clustering = AgglomerativeClustering(n_clusters=num_clusters).fit(data.loc[filtered_columns.index,:])# data, df_pca_data\n",
    "#clustering = KMeans(n_clusters=num_clusters).fit(df_data)# data, df_pca_data\n",
    "print(clustering.labels_)\n",
    "print(\"time elapsed: \" + str(time.time()-start_time))\n",
    "cluster_list = np.array(clustering.labels_).tolist()\n",
    "tsne_pca['cluster'] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tsne_pca)\n",
    "for index, row in tsne_pca.iterrows():\n",
    "    print(row)\n",
    "    print(type(row.iloc[2]))\n",
    "tsne_pca.to_csv(os.path.join(CONFIG.CSV_PATH, 'clustered_' + target_dataset + '.csv'), encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_spectral_clustering(dataframe, markersize=None):\n",
    "    # plot spectrac clustering result\n",
    "    # without label\n",
    "    #scatterplot_pointlabels(dataframe[['x', 'y']], markersize)\n",
    "    # better colors\n",
    "    plt.figure(figsize=(13.2,9.6))\n",
    "    color_dict = {v: k for v, k in enumerate(sns.color_palette(\"Paired\", num_clusters))}\n",
    "    sns_plot = sns.scatterplot(x=\"x\", y=\"y\", hue='cluster_id', palette=color_dict, data=dataframe, marker='.', s=30)\n",
    "    plt.savefig(os.path.join(CONFIG.SVG_PATH, 'spectralclustering_' + target_dataset + '.svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put clustering info into df\n",
    "df_clustered_spectral = pd.DataFrame({'x': tsne_pca.tsne1.squeeze(), \n",
    "                                      'y': tsne_pca.tsne2.squeeze(), \n",
    "                                      'word': tsne_pca.index.tolist(), \n",
    "                                      'cluster_id': clustering.labels_})\n",
    "# debug prints\n",
    "# print(df_clustered_spectral.shape)\n",
    "print(df_clustered_spectral.dtypes)\n",
    "plot_spectral_clustering(df_clustered_spectral, 0.2)       \n",
    "#ds_clustered_spectral = downsampling(df_clustered_spectral, 5000)\n",
    "#plot_spectral_clustering(ds_clustered_spectral, 0.2)       \n",
    "# print(df_clustered_spectral.iloc[:10, :])\n",
    "# df_clustered_spectral['cluster_id'].describe() # 30 integer clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
