{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bcbe309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe295821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['photos']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('yelp-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58657d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.read_json('yelp_dataset_10000.json')\n",
    "label_mapping = {label: idx for idx, label in enumerate(fdf['label'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b77fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['inside', 'outside', 'food', 'drink', 'menu'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffeeed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame (replace this with your actual DataFrame)\n",
    "df = pd.DataFrame({'photo_path': fdf['photo_path'].tolist(),\n",
    "                   'caption': fdf['caption'], \n",
    "                   'label': fdf['labelidx']})\n",
    "\n",
    "# Split data into Test (20%) and Temp (80%) sets\n",
    "temp_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split Temp into Train (60% of original) and Validation (20% of original)\n",
    "train_df, val_df = train_test_split(temp_df, test_size=0.25, random_state=42)\n",
    "\n",
    "# Custom Dataset class\n",
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None, tokenizer=None):\n",
    "        self.data = dataframe\n",
    "        self.transform = transform\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx, 0]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.data.iloc[idx, 2]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        caption = self.data.iloc[idx, 1]\n",
    "        text_encoded = self.tokenizer(caption, return_tensors='pt', truncation=True, padding='max_length', max_length=128)\n",
    "        \n",
    "        for key in text_encoded:\n",
    "            text_encoded[key] = text_encoded[key].squeeze(0)\n",
    "        \n",
    "        return image, text_encoded, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(224),     # Center crop to 1:1 aspect ratio (224x224)\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224 (if needed to enforce size)\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "# Initialize DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Create Dataset instances for training, validation, and test sets\n",
    "train_dataset = MultiModalDataset(dataframe=train_df, transform=transform, tokenizer=tokenizer)\n",
    "val_dataset = MultiModalDataset(dataframe=val_df, transform=transform, tokenizer=tokenizer)\n",
    "test_dataset = MultiModalDataset(dataframe=test_df, transform=transform, tokenizer=tokenizer)\n",
    "\n",
    "# Create DataLoaders for each set\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe3299e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d51ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16da672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['label']==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f0c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightweightMultiModalClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LightweightMultiModalClassifier, self).__init__()\n",
    "        # Load pretrained SqueezeNet and freeze its parameters\n",
    "        self.squeezenet = models.squeezenet1_1(pretrained=True)\n",
    "        for param in self.squeezenet.parameters():\n",
    "            param.requires_grad = False  # Freeze SqueezeNet\n",
    "        \n",
    "        # Modify SqueezeNet's classifier to output 256 features\n",
    "        # The final output of SqueezeNet is 512 channels for its feature extractor\n",
    "        self.squeezenet.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Conv2d(512, 256, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        # Load TinyBERT and freeze its parameters\n",
    "        self.bert = AutoModel.from_pretrained('prajjwal1/bert-tiny')\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False  # Freezes TinyBERT\n",
    "        \n",
    "        self.fc_text = nn.Linear(128, 256)  # TinyBERT has a hidden size of 128\n",
    "        \n",
    "        # Combined classifier with smaller fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, text):\n",
    "        # Image processing with SqueezeNet\n",
    "        image_features = self.squeezenet(image)\n",
    "        \n",
    "        # Text processing with TinyBERT\n",
    "        text_features = self.bert(**text).last_hidden_state[:, 0, :]  # Using CLS token\n",
    "        text_features = self.fc_text(text_features)\n",
    "        \n",
    "        # Combine and classify\n",
    "        combined_features = torch.cat((image_features, text_features), dim=1)\n",
    "        output = self.fc(combined_features)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "530879a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TinyBERT tokenizer\n",
    "#tokenizer = AutoTokenizer.from_pretrained('prajjwal1/bert-tiny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b9c5d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smhan/.conda/envs/libcity/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/home/smhan/.conda/envs/libcity/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Prepare the model, loss function, and optimizer\n",
    "num_classes = len(label_mapping)\n",
    "model = LightweightMultiModalClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45bde3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the model\n",
    "def save_model(model, optimizer, epoch, path=\"lightweight_multimodal_model_HJ.pth\"):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, path)\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model, optimizer, path=\"lightweight_multimodal_model.pth\"):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    return model, optimizer, start_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40710d66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:17<00:00,  1.34it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.45it/s]\n",
      "  0%|                                                                                            | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.7453, Val Loss: 0.4328, Val Accuracy: 85.50%\n",
      "Validation loss improved; model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:16<00:00,  1.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.46it/s]\n",
      "  0%|                                                                                            | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Train Loss: 0.3720, Val Loss: 0.3474, Val Accuracy: 88.20%\n",
      "Validation loss improved; model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:16<00:00,  1.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.45it/s]\n",
      "  0%|                                                                                            | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Train Loss: 0.3029, Val Loss: 0.2839, Val Accuracy: 90.20%\n",
      "Validation loss improved; model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:16<00:00,  1.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.46it/s]\n",
      "  0%|                                                                                            | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Train Loss: 0.2597, Val Loss: 0.2773, Val Accuracy: 90.15%\n",
      "Validation loss improved; model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:16<00:00,  1.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.46it/s]\n",
      "  0%|                                                                                            | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Train Loss: 0.2674, Val Loss: 0.2729, Val Accuracy: 90.50%\n",
      "Validation loss improved; model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:16<00:00,  1.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.45it/s]\n",
      "  0%|                                                                                            | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Train Loss: 0.2389, Val Loss: 0.2635, Val Accuracy: 90.70%\n",
      "Validation loss improved; model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:16<00:00,  1.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.44it/s]\n",
      "  0%|                                                                                            | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Train Loss: 0.2243, Val Loss: 0.2747, Val Accuracy: 90.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:16<00:00,  1.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.46it/s]\n",
      "  0%|                                                                                            | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Train Loss: 0.2088, Val Loss: 0.2589, Val Accuracy: 90.10%\n",
      "Validation loss improved; model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:16<00:00,  1.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.46it/s]\n",
      "  0%|                                                                                            | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Train Loss: 0.1935, Val Loss: 0.2462, Val Accuracy: 90.75%\n",
      "Validation loss improved; model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:16<00:00,  1.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.46it/s]\n",
      "  0%|                                                                                            | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train Loss: 0.1836, Val Loss: 0.2579, Val Accuracy: 91.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:16<00:00,  1.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.47it/s]\n",
      "  0%|                                                                                            | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Train Loss: 0.1845, Val Loss: 0.2890, Val Accuracy: 90.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:16<00:00,  1.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.46it/s]\n",
      "  0%|                                                                                            | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Train Loss: 0.1781, Val Loss: 0.2629, Val Accuracy: 90.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:16<00:00,  1.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.46it/s]\n",
      "  0%|                                                                                            | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Train Loss: 0.1922, Val Loss: 0.2568, Val Accuracy: 91.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:16<00:00,  1.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.45it/s]\n",
      "  0%|                                                                                            | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Train Loss: 0.1573, Val Loss: 0.2582, Val Accuracy: 91.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:16<00:00,  1.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.46it/s]\n",
      "  0%|                                                                                            | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Train Loss: 0.1601, Val Loss: 0.2846, Val Accuracy: 90.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:16<00:00,  1.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.45it/s]\n",
      "  0%|                                                                                            | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Train Loss: 0.1599, Val Loss: 0.2498, Val Accuracy: 91.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:16<00:00,  1.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.46it/s]\n",
      "  0%|                                                                                            | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Train Loss: 0.1480, Val Loss: 0.2587, Val Accuracy: 91.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:16<00:00,  1.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.47it/s]\n",
      "  0%|                                                                                            | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Train Loss: 0.1285, Val Loss: 0.2563, Val Accuracy: 91.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 24/24 [00:16<00:00,  1.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Train Loss: 0.1431, Val Loss: 0.2997, Val Accuracy: 90.45%\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 10  # Number of epochs to wait for improvement\n",
    "min_val_loss = np.Inf\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Training loop with early stopping\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, texts, labels in tqdm.tqdm(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        texts = {k: v.to(device) for k, v in texts.items()}\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, texts, labels in tqdm.tqdm(val_loader):  # Assuming val_loader is defined\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            texts = {k: v.to(device) for k, v in texts.items()}\n",
    "\n",
    "            outputs = model(images, texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    # Calculate average validation loss and accuracy\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "    \n",
    "    # Early stopping\n",
    "    if avg_val_loss < min_val_loss:\n",
    "        min_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        save_model(model, optimizer, epoch)  # Save the best model\n",
    "        print(f\"Validation loss improved; model saved.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31b2d537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from epoch 9\n"
     ]
    }
   ],
   "source": [
    "# Load the model and optimizer\n",
    "model, optimizer, start_epoch = load_model(model, optimizer, path=\"lightweight_multimodal_model_HJ.pth\")\n",
    "print(f\"Resuming from epoch {start_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c2328d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 91.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Variables to track the total loss and accuracy\n",
    "total_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "# Use no_grad context as we are not training, only evaluating\n",
    "with torch.no_grad():\n",
    "    for images, texts, labels in tqdm.tqdm(test_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        texts = {k: v.to(device) for k, v in texts.items()}\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images, texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "# Calculate average loss and accuracy\n",
    "average_loss = total_loss / len(test_loader)\n",
    "accuracy = correct_predictions / total_samples\n",
    "\n",
    "# print(f\"Test Loss: {average_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "969d0191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os: posix\n",
      "numpy: 1.19.4\n",
      "torch: 1.13.1+cu117\n",
      "pandas: 1.1.5\n",
      "tqdm: 4.60.0\n",
      "torchvision: 0.14.1+cu117\n",
      "PIL: 9.5.0\n",
      "transformers: transformers\n",
      "scikit-learn: 0.24.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import __version__ as sklearn_version\n",
    "import torchvision\n",
    "\n",
    "# version check\n",
    "def print_versions():\n",
    "    print(f\"os: {os.name}\")\n",
    "    print(f\"numpy: {np.__version__}\")\n",
    "    print(f\"torch: {torch.__version__}\")\n",
    "    print(f\"pandas: {pd.__version__}\")\n",
    "    print(f\"tqdm: {tqdm.__version__}\")\n",
    "    print(f\"torchvision: {torchvision.__version__}\")\n",
    "    print(f\"PIL: {Image.__version__}\")\n",
    "    print(f\"transformers: {DistilBertModel.__module__.split('.')[0]}\")  # transformers의 주요 버전\n",
    "    print(f\"scikit-learn: {sklearn_version}\")\n",
    "\n",
    "# 버전 정보 출력\n",
    "print_versions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libcity",
   "language": "python",
   "name": "libcity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
